{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07_cyclegan.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"18PPW8wJPuKB6Hq0VG5LqMXuB6efmDBRv","authorship_tag":"ABX9TyPtRZ3rb36T5qM5zDdd0Xy7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hdXTZWxdRlr4","colab_type":"text"},"source":["## CycleGAN で PyTorch実装を学ぶ\n","- Reference\n","  - https://github.com/eriklindernoren/PyTorch-GAN\n","  - https://github.com/eriklindernoren/PyTorch-GAN/tree/master/implementations/cyclegan\n","  "]},{"cell_type":"code","metadata":{"id":"wNzTRQlrRdQv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021438600,"user_tz":-540,"elapsed":1219,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import os\n","import datetime\n","import numpy as np\n","import pandas as pd\n","import itertools"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcuP0KtLR1sZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021440325,"user_tz":-540,"elapsed":1175,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import torchvision.transforms as transforms\n","from torchvision.utils import save_image, make_grid"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-Frrihw_qCD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021440326,"user_tz":-540,"elapsed":787,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxFYcNcZ_u63","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021441546,"user_tz":-540,"elapsed":1729,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for model\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"cymjIFCBWngT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021441547,"user_tz":-540,"elapsed":1523,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for datasets\n","\n","import glob\n","import random\n","#import os\n","#import numpy as np\n","\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import torchvision.transforms as transforms"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYW7Q1oD_xr5","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021441549,"user_tz":-540,"elapsed":1305,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#torch.__version__"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJaCA6PT_0JC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021442294,"user_tz":-540,"elapsed":1790,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/project/ML/pytorch-gan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '07_out')"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I4pzsl1AugF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021442294,"user_tz":-540,"elapsed":1722,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"1bxrWFV4A9cn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021442295,"user_tz":-540,"elapsed":1587,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["cuda = True if torch.cuda.is_available() else False"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7G-Z0fQW-ED","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021442296,"user_tz":-540,"elapsed":1447,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm2d') != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8bfdAxdXmeA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021442302,"user_tz":-540,"elapsed":1332,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.block = nn.Sequential(\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(in_features, in_features, 3),\n","            nn.InstanceNorm2d(in_features),\n","            nn.ReLU(inplace=True),\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(in_features, in_features, 3),\n","            nn.InstanceNorm2d(in_features),\n","        )\n","\n","    def forward(self, x):\n","        return x + self.block(x)\n","\n","\n","class GeneratorResNet(nn.Module):\n","    def __init__(self, input_shape, num_residual_blocks):\n","        super(GeneratorResNet, self).__init__()\n","\n","        channels = input_shape[0]\n","\n","        # Initial convolution block\n","        out_features = 64\n","\n","        model = [\n","            nn.ReflectionPad2d(channels),\n","            nn.Conv2d(channels, out_features, 7),\n","            nn.InstanceNorm2d(out_features),\n","            nn.ReLU(inplace=True),\n","        ]\n","\n","        in_features = out_features\n","\n","        # Downsampling\n","        for _ in range(2):\n","            out_features *= 2\n","            model += [\n","                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(inplace=True),\n","            ]\n","            in_features = out_features\n","\n","        # Residual blocks\n","        for _ in range(num_residual_blocks):\n","            model += [ResidualBlock(out_features)]\n","\n","        # Upsampling\n","        for _ in range(2):\n","            out_features //= 2\n","\n","            model += [\n","                nn.Upsample(scale_factor=2),\n","                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(inplace=True),\n","            ]\n","\n","            in_features = out_features\n","\n","        # Output layer\n","        model += [nn.ReflectionPad2d(channels), nn.Conv2d(out_features, channels, 7), nn.Tanh()]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        return self.model(x)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHFH9tmsChqv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021442648,"user_tz":-540,"elapsed":1573,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class Discriminator(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Discriminator, self).__init__()\n","\n","        channels, height, width = input_shape\n","\n","        # Calculate output shape of image discriminator (PatchGAN)\n","        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n","\n","        def discriminator_block(in_filters, out_filters, normalize=True):\n","            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n","            layers = [\n","                nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)\n","            ]\n","\n","            if normalize:\n","                layers.append(nn.InstanceNorm2d(out_filters))\n","\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","\n","            return layers\n","\n","        self.model = nn.Sequential(\n","            *discriminator_block(channels, 64, normalize=False),\n","            *discriminator_block(64, 128),\n","            *discriminator_block(128, 256),\n","            *discriminator_block(256, 512),\n","            nn.ZeroPad2d((1, 0, 1, 0)),\n","            nn.Conv2d(512, 1, 4, padding=1)\n","        )\n","\n","    def forward(self, img):\n","        return self.model(img)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"P67riG4jXANz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600021442650,"user_tz":-540,"elapsed":1417,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class ReplayBuffer:\n","    def __init__(self, max_size=50):\n","        assert max_size > 0, \"Empty buffer or trying to create a black hole. Be careful.\"\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def push_and_pop(self, data):\n","        to_return = []\n","        for element in data.data:\n","            element = torch.unsqueeze(element, 0)\n","            if len(self.data) < self.max_size:\n","                self.data.append(element)\n","                to_return.append(element)\n","            else:\n","                if random.uniform(0, 1) > 0.5:\n","                    i = random.randint(0, self.max_size - 1)\n","                    to_return.append(self.data[i].clone())\n","                    self.data[i] = element\n","                else:\n","                    to_return.append(element)\n","        return Variable(torch.cat(to_return))\n","\n","\n","class LambdaLR:\n","    def __init__(self, n_epochs, offset, decay_start_epoch):\n","        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n","        self.n_epochs = n_epochs\n","        self.offset = offset\n","        self.decay_start_epoch = decay_start_epoch\n","\n","    def step(self, epoch):\n","        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCsUq86WSRg4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600023739496,"user_tz":-540,"elapsed":1698,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CycleGAN:\n","    def __init__(self, data_loader, val_data_loader, input_shape, n_residual_blocks=9):\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'batche_i',\n","            'loss_D', 'loss_G', 'loss_GAN', 'loss_cycle', 'loss_identity'\n","            'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.generator_name = 'generator_model'\n","        self.train_cnt = 0\n","\n","        self.data_loader = data_loader\n","        self.val_data_loader = val_data_loader\n","        self.input_shape = input_shape\n","        self.n_residual_blocks = n_residual_blocks\n","        self.lambda_cyc = 10.0\n","        self.lambda_id = 5.0\n","\n","        # Losses\n","        self.criterion_GAN = torch.nn.MSELoss()\n","        self.criterion_cycle = torch.nn.L1Loss()\n","        self.criterion_identity = torch.nn.L1Loss()\n","\n","        # Initialize generator and discriminator\n","        self.G_AB = GeneratorResNet(self.input_shape, self.n_residual_blocks)\n","        self.G_BA = GeneratorResNet(self.input_shape, self.n_residual_blocks)\n","        self.D_A = Discriminator(self.input_shape)\n","        self.D_B = Discriminator(self.input_shape)\n","\n","        if cuda:\n","            self.G_AB = self.G_AB.cuda()\n","            self.G_BA = self.G_BA.cuda()\n","            self.D_A = self.D_A.cuda()\n","            self.D_B = self.D_B.cuda()\n","            self.criterion_GAN.cuda()\n","            self.criterion_cycle.cuda()\n","            self.criterion_identity.cuda()\n","\n","        # if opt.epoch != 0:\n","        #     # Load pretrained models\n","        #     G_AB.load_state_dict(torch.load(\"saved_models/%s/G_AB_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     G_BA.load_state_dict(torch.load(\"saved_models/%s/G_BA_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     D_A.load_state_dict(torch.load(\"saved_models/%s/D_A_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     D_B.load_state_dict(torch.load(\"saved_models/%s/D_B_%d.pth\" % (self.dataset_name, self.epoch)))\n","        # Initialize weights\n","        self.G_AB.apply(weights_init_normal)\n","        self.G_BA.apply(weights_init_normal)\n","        self.D_A.apply(weights_init_normal)\n","        self.D_B.apply(weights_init_normal)\n","\n","        self.lr = 0.0002\n","        self.b1 = 0.5\n","        self.b2 = 0.999\n","\n","        # Optimizers\n","        self.optimizer_G = torch.optim.Adam(\n","            itertools.chain(self.G_AB.parameters(), self.G_BA.parameters()), lr=self.lr, betas=(self.b1, self.b2)\n","        )\n","        self.optimizer_D_A = torch.optim.Adam(self.D_A.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n","        self.optimizer_D_B = torch.optim.Adam(self.D_B.parameters(), lr=self.lr, betas=(self.b1, self.b2))\n","\n","        self.Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","\n","        # Buffers of previously generated samples\n","        self.fake_A_buffer = ReplayBuffer()\n","        self.fake_B_buffer = ReplayBuffer()\n","\n","    def train(self, n_epochs, decay_epoch, sample_interval=-1):\n","        epoch = 0\n","\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        step_cnt = 1\n","\n","        # Learning rate update schedulers\n","        lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n","            self.optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n","        )\n","        lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n","            self.optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n","        )\n","        lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n","            self.optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n","        )\n","\n","        for epoch_i in range(epoch+1, n_epochs+1):\n","\n","            for batch_i, batch in enumerate(self.data_loader, 1):\n","                # Set model input\n","                real_A = Variable(batch[\"A\"].type(self.Tensor))\n","                real_B = Variable(batch[\"B\"].type(self.Tensor))\n","\n","                # Adversarial ground truths\n","                valid = Variable(self.Tensor(np.ones((real_A.size(0), *self.D_A.output_shape))), requires_grad=False)\n","                fake  = Variable(self.Tensor(np.zeros((real_A.size(0), *self.D_A.output_shape))), requires_grad=False)\n","\n","                # Train Generator\n","                self.G_AB.train()\n","                self.G_BA.train()\n","\n","                self.optimizer_G.zero_grad()\n","\n","                # Identity loss\n","                loss_id_A = self.criterion_identity(self.G_BA(real_A), real_A)\n","                loss_id_B = self.criterion_identity(self.G_AB(real_B), real_B)\n","\n","                loss_identity = (loss_id_A + loss_id_B) / 2\n","\n","                # GAN loss\n","                fake_B = self.G_AB(real_A)\n","                loss_GAN_AB = self.criterion_GAN(self.D_B(fake_B), valid)\n","                fake_A = self.G_BA(real_B)\n","                loss_GAN_BA = self.criterion_GAN(self.D_A(fake_A), valid)\n","\n","                loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n","\n","                # Cycle loss\n","                recov_A = self.G_BA(fake_B)\n","                loss_cycle_A = self.criterion_cycle(recov_A, real_A)\n","                recov_B = self.G_AB(fake_A)\n","                loss_cycle_B = self.criterion_cycle(recov_B, real_B)\n","\n","                loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n","\n","                # Total loss\n","                loss_G = loss_GAN + self.lambda_cyc * loss_cycle + self.lambda_id * loss_identity\n","\n","                loss_G.backward()\n","                self.optimizer_G.step()\n","\n","                # Train Discriminator A\n","                self.optimizer_D_A.zero_grad()\n","\n","                # Real loss\n","                loss_real = self.criterion_GAN(self.D_A(real_A), valid)\n","                # Fake loss (on batch of previously generated samples)\n","                fake_A_ = self.fake_A_buffer.push_and_pop(fake_A)\n","                loss_fake = self.criterion_GAN(self.D_A(fake_A_.detach()), fake)\n","                # Total loss\n","                loss_D_A = (loss_real + loss_fake) / 2\n","\n","                loss_D_A.backward()\n","                self.optimizer_D_A.step()\n","\n","                # Train Discriminator B\n","                self.optimizer_D_B.zero_grad()\n","\n","                # Real loss\n","                loss_real = self.criterion_GAN(self.D_B(real_B), valid)\n","                # Fake loss (on batch of previously generated samples)\n","                fake_B_ = self.fake_B_buffer.push_and_pop(fake_B)\n","                loss_fake = self.criterion_GAN(self.D_B(fake_B_.detach()), fake)\n","                # Total loss\n","                loss_D_B = (loss_real + loss_fake) / 2\n","\n","                loss_D_B.backward()\n","                self.optimizer_D_B.step()\n","\n","                loss_D = (loss_D_A + loss_D_B) / 2\n","\n","                # Log Progress\n","                batches_done = epoch_i * len(self.data_loader) + batch_i\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                self.history = self.history.append({\n","                    'epoch': epoch_i,\n","                    'batch_i': batch_i,\n","                    'loss_D':loss_D.item(),\n","                    'loss_G': loss_G.item(),\n","                    'loss_GAN': loss_GAN.item(),\n","                    'loss_cycle': loss_cycle.item(),\n","                    'loss_identity': loss_identity.item(),\n","                    'elapsed_time': elapsed_time\n","                }, ignore_index=True)\n","\n","\n","                if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                    print(\n","                        '[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] %s'\n","                        % (\n","                            epoch_i,\n","                            n_epochs,\n","                            batch_i,\n","                            len(self.data_loader),\n","                            loss_D.item(),\n","                            loss_G.item(),\n","                            loss_GAN.item(),\n","                            loss_cycle.item(),\n","                            loss_identity.item(),\n","                            elapsed_time\n","                        )\n","                    )\n","                    # sys.stdout.write(\n","                    #     \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n","                    #     % (\n","                    #         epoch,\n","                    #         opt.n_epochs,\n","                    #         i,\n","                    #         len(dataloader),\n","                    #         loss_D.item(),\n","                    #         loss_G.item(),\n","                    #         loss_GAN.item(),\n","                    #         loss_cycle.item(),\n","                    #         loss_identity.item(),\n","                    #         time_left,\n","                    #     )\n","                    # )\n","\n","                    self.sample_images(epoch, batch_i, 1)\n","\n","                # Update learning rates\n","                lr_scheduler_G.step()\n","                lr_scheduler_D_A.step()\n","                lr_scheduler_D_B.step()\n","\n","                step_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    def sample_images(self, epoch, batch_i, n_row=1):\n","        \"\"\"Saves a generated sample from the test set\"\"\"\n","        imgs = next(iter(self.val_data_loader))\n","        self.G_AB.eval()\n","        self.G_BA.eval()\n","        real_A = Variable(imgs[\"A\"].type(self.Tensor))\n","        fake_B = self.G_AB(real_A)\n","        real_B = Variable(imgs[\"B\"].type(self.Tensor))\n","        fake_A = self.G_BA(real_B)\n","\n","        # Arange images along x-axis\n","        real_A = make_grid(real_A, nrow=n_row, normalize=True)\n","        real_B = make_grid(real_B, nrow=n_row, normalize=True)\n","        fake_A = make_grid(fake_A, nrow=n_row, normalize=True)\n","        fake_B = make_grid(fake_B, nrow=n_row, normalize=True)\n","\n","        # Arange images along y-axis\n","        image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n","        file_name = os.path.join(self.img_save_dir, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        save_image(image_grid, file_name, normalize=True)\n","\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['loss_D', 'loss_G']\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_state_dict(self.generator, self.generator_name, file_suffix)\n","\n","    def save_state_dict(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_model_file_name(model_name, file_suffix))\n","        torch.save(model.state_dict(), file_path)\n","        print('Model saved.', model_name)\n","\n","    def _create_model_file_name(self, model_name, suffix=None):\n","        processor = 'gpu' if cuda else 'cpu'\n","\n","        if suffix:\n","            return '{}_{}_{}.pth'.format(model_name, processor, suffix)\n","        else:\n","            return '{}_{}.pth'.format(model_name, processor)"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OuW8T06bf8g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600023739497,"user_tz":-540,"elapsed":1066,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["def to_rgb(image):\n","    rgb_image = Image.new(\"RGB\", image.size)\n","    rgb_image.paste(image)\n","    return rgb_image\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):\n","        self.transform = transforms.Compose(transforms_)\n","        self.unaligned = unaligned\n","\n","        self.files_A = sorted(glob.glob(os.path.join(root, \"%s/A\" % mode) + \"/*.*\"))\n","        self.files_B = sorted(glob.glob(os.path.join(root, \"%s/B\" % mode) + \"/*.*\"))\n","\n","    def __getitem__(self, index):\n","        image_A = Image.open(self.files_A[index % len(self.files_A)])\n","\n","        if self.unaligned:\n","            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n","        else:\n","            image_B = Image.open(self.files_B[index % len(self.files_B)])\n","\n","        # Convert grayscale images to rgb\n","        if image_A.mode != \"RGB\":\n","            image_A = to_rgb(image_A)\n","        if image_B.mode != \"RGB\":\n","            image_B = to_rgb(image_B)\n","\n","        item_A = self.transform(image_A)\n","        item_B = self.transform(image_B)\n","        return {\"A\": item_A, \"B\": item_B}\n","\n","    def __len__(self):\n","        return max(len(self.files_A), len(self.files_B))"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"ic97OtIOEVGR","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600023739946,"user_tz":-540,"elapsed":580,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# Configure data loader\n","dataset_name = 'apple2orange'\n","img_root_path = os.path.join(DATA_DIR_PATH, dataset_name)\n","channels = 3\n","img_height = 256\n","img_width = 256\n","input_shape = (channels, img_height, img_width)\n","batch_size = 1\n","n_cpu = 8\n","\n","# Image transformations\n","transforms_ = [\n","    transforms.Resize(int(img_height * 1.12), Image.BICUBIC),\n","    transforms.RandomCrop((img_height, img_width)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","]\n","\n","# Training data loader\n","dataloader = DataLoader(\n","    ImageDataset(img_root_path, transforms_=transforms_, unaligned=True),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=n_cpu,\n",")\n","\n","# Test data loader\n","val_dataloader = DataLoader(\n","    ImageDataset(img_root_path, transforms_=transforms_, unaligned=True, mode='test'),\n","    batch_size=5,\n","    shuffle=True,\n","    num_workers=1,\n",")"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0oP_OUFIDYJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":440},"executionInfo":{"status":"error","timestamp":1600023767024,"user_tz":-540,"elapsed":24144,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"42f5628f-d95f-4487-ed57-7aa14dd413bc"},"source":["n_epochs = 1\n","decay_epoch = 0\n","sample_interval = 50\n","\n","gan = CycleGAN(dataloader, val_dataloader, input_shape)\n","gan.train(n_epochs, decay_epoch, sample_interval)"],"execution_count":91,"outputs":[{"output_type":"stream","text":["2020-09-13T19:02:23.401647 Start 1\n","[Epoch 1/1] [Batch 50/1019] [D loss: 3257716.500000] [G loss: 3089213.000000, adv: 3089196.000000, cycle: 1.224994, identity: 0.959382] 0:00:12.478332\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-91-8b4fb72fabdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_hisotry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-88-a255e39aca58>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, decay_epoch, sample_interval)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;31m# )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# Update learning rates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-88-a255e39aca58>\u001b[0m in \u001b[0;36msample_images\u001b[0;34m(self, epoch, batch_i, n_row)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_AB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mreal_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mfake_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_BA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Arange images along x-axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-43-08cac2caa0ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor)\u001b[0m\n\u001b[1;32m   3141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nearest'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nearest'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 15.75 GiB total capacity; 14.14 GiB already allocated; 24.88 MiB free; 14.57 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"neqHPmwJoz9H","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600021443493,"user_tz":-540,"elapsed":1550,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["gan.plot_hisotry()\n","\n","gan.save_models()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P95nomvfwHrb","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1600021443494,"user_tz":-540,"elapsed":1520,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":[""],"execution_count":null,"outputs":[]}]}