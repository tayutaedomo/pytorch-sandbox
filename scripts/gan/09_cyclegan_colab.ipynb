{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"09_cyclegan_colab.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"127Mh-in7IayruybnLIHA6hDbZalA2adA","authorship_tag":"ABX9TyOOoz4n8XFSZCDhpyrJBPNL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hdXTZWxdRlr4"},"source":["## CycleGAN PyTorch実装を学ぶ\n","- Reference\n","  - https://github.com/eriklindernoren/PyTorch-GAN/tree/master/implementations/cyclegan\n","  "]},{"cell_type":"code","metadata":{"id":"wNzTRQlrRdQv","executionInfo":{"status":"ok","timestamp":1603099105764,"user_tz":-540,"elapsed":1194,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import os\n","import sys\n","import datetime\n","import time\n","import numpy as np\n","import pandas as pd\n","import itertools"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcuP0KtLR1sZ","executionInfo":{"status":"ok","timestamp":1603099110386,"user_tz":-540,"elapsed":5809,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import torchvision.transforms as transforms\n","from torchvision.utils import save_image, make_grid"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-Frrihw_qCD","executionInfo":{"status":"ok","timestamp":1603099110386,"user_tz":-540,"elapsed":5805,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxFYcNcZ_u63","executionInfo":{"status":"ok","timestamp":1603099110387,"user_tz":-540,"elapsed":5801,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for model\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cymjIFCBWngT","executionInfo":{"status":"ok","timestamp":1603099110388,"user_tz":-540,"elapsed":5798,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for datasets\n","\n","import glob\n","import random\n","#import os\n","#import numpy as np\n","\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import torchvision.transforms as transforms"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYW7Q1oD_xr5","executionInfo":{"status":"ok","timestamp":1603099110389,"user_tz":-540,"elapsed":5795,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#torch.__version__"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"lJaCA6PT_0JC","executionInfo":{"status":"ok","timestamp":1603099110389,"user_tz":-540,"elapsed":5791,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/project/ML/pytorch-gan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '09_out')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I4pzsl1AugF","executionInfo":{"status":"ok","timestamp":1603099111332,"user_tz":-540,"elapsed":6730,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Biak12bPDuZ1","executionInfo":{"status":"ok","timestamp":1603099111333,"user_tz":-540,"elapsed":6727,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["def to_rgb(image):\n","    rgb_image = Image.new(\"RGB\", image.size)\n","    rgb_image.paste(image)\n","    return rgb_image\n","\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):\n","        self.transform = transforms.Compose(transforms_)\n","        self.unaligned = unaligned\n","\n","        self.files_A = sorted(glob.glob(os.path.join(root, \"%s/A\" % mode) + \"/*.*\"))\n","        self.files_B = sorted(glob.glob(os.path.join(root, \"%s/B\" % mode) + \"/*.*\"))\n","\n","    def __getitem__(self, index):\n","        image_A = Image.open(self.files_A[index % len(self.files_A)])\n","\n","        if self.unaligned:\n","            image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)])\n","        else:\n","            image_B = Image.open(self.files_B[index % len(self.files_B)])\n","\n","        # Convert grayscale images to rgb\n","        if image_A.mode != \"RGB\":\n","            image_A = to_rgb(image_A)\n","        if image_B.mode != \"RGB\":\n","            image_B = to_rgb(image_B)\n","\n","        item_A = self.transform(image_A)\n","        item_B = self.transform(image_B)\n","        return {\"A\": item_A, \"B\": item_B}\n","\n","    def __len__(self):\n","        return max(len(self.files_A), len(self.files_B))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWa86JwqD6jT","executionInfo":{"status":"ok","timestamp":1603099111333,"user_tz":-540,"elapsed":6723,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class ReplayBuffer:\n","    def __init__(self, max_size=50):\n","        assert max_size > 0, \"Empty buffer or trying to create a black hole. Be careful.\"\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def push_and_pop(self, data):\n","        to_return = []\n","        for element in data.data:\n","            element = torch.unsqueeze(element, 0)\n","            if len(self.data) < self.max_size:\n","                self.data.append(element)\n","                to_return.append(element)\n","            else:\n","                if random.uniform(0, 1) > 0.5:\n","                    i = random.randint(0, self.max_size - 1)\n","                    to_return.append(self.data[i].clone())\n","                    self.data[i] = element\n","                else:\n","                    to_return.append(element)\n","        return Variable(torch.cat(to_return))\n","\n","\n","class LambdaLR:\n","    def __init__(self, n_epochs, offset, decay_start_epoch):\n","        assert (n_epochs - decay_start_epoch) > 0, \"Decay must start before the training session ends!\"\n","        self.n_epochs = n_epochs\n","        self.offset = offset\n","        self.decay_start_epoch = decay_start_epoch\n","\n","    def step(self, epoch):\n","        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"KB4uz76ED_RA","executionInfo":{"status":"ok","timestamp":1603099111335,"user_tz":-540,"elapsed":6721,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","        if hasattr(m, \"bias\") and m.bias is not None:\n","            torch.nn.init.constant_(m.bias.data, 0.0)\n","    elif classname.find(\"BatchNorm2d\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)\n","\n","\n","##############################\n","#           RESNET\n","##############################\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.block = nn.Sequential(\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(in_features, in_features, 3),\n","            nn.InstanceNorm2d(in_features),\n","            nn.ReLU(inplace=True),\n","            nn.ReflectionPad2d(1),\n","            nn.Conv2d(in_features, in_features, 3),\n","            nn.InstanceNorm2d(in_features),\n","        )\n","\n","    def forward(self, x):\n","        return x + self.block(x)\n","\n","\n","class GeneratorResNet(nn.Module):\n","    def __init__(self, input_shape, num_residual_blocks):\n","        super(GeneratorResNet, self).__init__()\n","\n","        channels = input_shape[0]\n","\n","        # Initial convolution block\n","        out_features = 64\n","        model = [\n","            nn.ReflectionPad2d(channels),\n","            nn.Conv2d(channels, out_features, 7),\n","            nn.InstanceNorm2d(out_features),\n","            nn.ReLU(inplace=True),\n","        ]\n","        in_features = out_features\n","\n","        # Downsampling\n","        for _ in range(2):\n","            out_features *= 2\n","            model += [\n","                nn.Conv2d(in_features, out_features, 3, stride=2, padding=1),\n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(inplace=True),\n","            ]\n","            in_features = out_features\n","\n","        # Residual blocks\n","        for _ in range(num_residual_blocks):\n","            model += [ResidualBlock(out_features)]\n","\n","        # Upsampling\n","        for _ in range(2):\n","            out_features //= 2\n","            model += [\n","                nn.Upsample(scale_factor=2),\n","                nn.Conv2d(in_features, out_features, 3, stride=1, padding=1),\n","                nn.InstanceNorm2d(out_features),\n","                nn.ReLU(inplace=True),\n","            ]\n","            in_features = out_features\n","\n","        # Output layer\n","        model += [nn.ReflectionPad2d(channels), nn.Conv2d(out_features, channels, 7), nn.Tanh()]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","\n","##############################\n","#        Discriminator\n","##############################\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, input_shape):\n","        super(Discriminator, self).__init__()\n","\n","        channels, height, width = input_shape\n","\n","        # Calculate output shape of image discriminator (PatchGAN)\n","        self.output_shape = (1, height // 2 ** 4, width // 2 ** 4)\n","\n","        def discriminator_block(in_filters, out_filters, normalize=True):\n","            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n","            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n","            if normalize:\n","                layers.append(nn.InstanceNorm2d(out_filters))\n","            layers.append(nn.LeakyReLU(0.2, inplace=True))\n","            return layers\n","\n","        self.model = nn.Sequential(\n","            *discriminator_block(channels, 64, normalize=False),\n","            *discriminator_block(64, 128),\n","            *discriminator_block(128, 256),\n","            *discriminator_block(256, 512),\n","            nn.ZeroPad2d((1, 0, 1, 0)),\n","            nn.Conv2d(512, 1, 4, padding=1)\n","        )\n","\n","    def forward(self, img):\n","        return self.model(img)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmnjU1JXEJoJ","executionInfo":{"status":"ok","timestamp":1603099111336,"user_tz":-540,"elapsed":6718,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class Option:\n","    def __init__(self):\n","        self.epoch = 0\n","        #self.n_epochs = 200\n","        self.n_epochs = 3\n","        #self.dataset_name = \"monet2photo\"\n","        self.dataset_name = \"apple2orange\"\n","        self.batch_size = 1\n","        self.lr = 0.0002\n","        self.b1 = 0.5\n","        self.b2 = 0.999\n","        #self.decay_epoch = 100\n","        self.decay_epoch = 2\n","        self.n_cpu = 8\n","        self.img_height = 256\n","        self.img_width = 256\n","        self.channels = 3\n","        self.sample_interval = 100\n","        self.checkpoint_interval = -1\n","        self.n_residual_blocks = 9\n","        self.lambda_cyc = 10.0\n","        self.lambda_id = 5.0\n","\n","opt = Option()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ycXHdasKFFH_","executionInfo":{"status":"ok","timestamp":1603099121661,"user_tz":-540,"elapsed":17039,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# Create sample and checkpoint directories\n","#os.makedirs(\"images/%s\" % opt.dataset_name, exist_ok=True)\n","os.makedirs(\"saved_models/%s\" % opt.dataset_name, exist_ok=True)\n","\n","# Losses\n","criterion_GAN = torch.nn.MSELoss()\n","criterion_cycle = torch.nn.L1Loss()\n","criterion_identity = torch.nn.L1Loss()\n","\n","cuda = torch.cuda.is_available()\n","\n","input_shape = (opt.channels, opt.img_height, opt.img_width)\n","\n","# Initialize generator and discriminator\n","G_AB = GeneratorResNet(input_shape, opt.n_residual_blocks)\n","G_BA = GeneratorResNet(input_shape, opt.n_residual_blocks)\n","D_A = Discriminator(input_shape)\n","D_B = Discriminator(input_shape)\n","\n","if cuda:\n","    G_AB = G_AB.cuda()\n","    G_BA = G_BA.cuda()\n","    D_A = D_A.cuda()\n","    D_B = D_B.cuda()\n","    criterion_GAN.cuda()\n","    criterion_cycle.cuda()\n","    criterion_identity.cuda()\n","\n","if opt.epoch != 0:\n","    # Load pretrained models\n","    G_AB.load_state_dict(torch.load(\"saved_models/%s/G_AB_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    G_BA.load_state_dict(torch.load(\"saved_models/%s/G_BA_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    D_A.load_state_dict(torch.load(\"saved_models/%s/D_A_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","    D_B.load_state_dict(torch.load(\"saved_models/%s/D_B_%d.pth\" % (opt.dataset_name, opt.epoch)))\n","else:\n","    # Initialize weights\n","    G_AB.apply(weights_init_normal)\n","    G_BA.apply(weights_init_normal)\n","    D_A.apply(weights_init_normal)\n","    D_B.apply(weights_init_normal)\n","\n","# Optimizers\n","optimizer_G = torch.optim.Adam(\n","    itertools.chain(G_AB.parameters(), G_BA.parameters()), lr=opt.lr, betas=(opt.b1, opt.b2)\n",")\n","optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n","\n","# Learning rate update schedulers\n","lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",")\n","lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",")\n","lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n","    optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step\n",")\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n","\n","# Buffers of previously generated samples\n","fake_A_buffer = ReplayBuffer()\n","fake_B_buffer = ReplayBuffer()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"1bxrWFV4A9cn","executionInfo":{"status":"ok","timestamp":1603099131578,"user_tz":-540,"elapsed":26950,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["img_root_path = os.path.join(DATA_DIR_PATH, opt.dataset_name)\n","#print(img_root_path)\n","\n","# Image transformations\n","transforms_ = [\n","    transforms.Resize(int(opt.img_height * 1.12), Image.BICUBIC),\n","    transforms.RandomCrop((opt.img_height, opt.img_width)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","]\n","\n","# Training data loader\n","dataloader = DataLoader(\n","    #ImageDataset(\"../../data/%s\" % opt.dataset_name, transforms_=transforms_, unaligned=True),\n","    ImageDataset(img_root_path, transforms_=transforms_, unaligned=True),\n","    batch_size=opt.batch_size,\n","    shuffle=True,\n","    num_workers=opt.n_cpu,\n",")\n","# Test data loader\n","val_dataloader = DataLoader(\n","    #ImageDataset(\"../../data/%s\" % opt.dataset_name, transforms_=transforms_, unaligned=True, mode=\"test\"),\n","    ImageDataset(img_root_path, transforms_=transforms_, unaligned=True, mode=\"test\"),\n","    batch_size=5,\n","    shuffle=True,\n","    num_workers=1,\n",")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"P95nomvfwHrb","executionInfo":{"status":"ok","timestamp":1603099258905,"user_tz":-540,"elapsed":837,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","\n","def sample_images(batches_done):\n","    \"\"\"Saves a generated sample from the test set\"\"\"\n","    imgs = next(iter(val_dataloader))\n","    G_AB.eval()\n","    G_BA.eval()\n","    real_A = Variable(imgs[\"A\"].type(Tensor))\n","    fake_B = G_AB(real_A)\n","    real_B = Variable(imgs[\"B\"].type(Tensor))\n","    fake_A = G_BA(real_B)\n","    # Arange images along x-axis\n","    real_A = make_grid(real_A, nrow=5, normalize=True)\n","    real_B = make_grid(real_B, nrow=5, normalize=True)\n","    fake_A = make_grid(fake_A, nrow=5, normalize=True)\n","    fake_B = make_grid(fake_B, nrow=5, normalize=True)\n","    # Arange images along y-axis\n","    image_grid = torch.cat((real_A, fake_B, real_B, fake_A), 1)\n","    #save_image(image_grid, \"images/%s/%s.png\" % (opt.dataset_name, batches_done), normalize=False)\n","    file_name = os.path.join(img_save_dir, '{}.png'.format(batches_done))\n","    save_image(image_grid, file_name, normalize=False)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5Xe7iEgIp74","executionInfo":{"status":"ok","timestamp":1603100142055,"user_tz":-540,"elapsed":881660,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"6f93c28c-af26-4356-cc48-4818599d879c","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["# ----------\n","#  Training\n","# ----------\n","\n","prev_time = time.time()\n","for epoch in range(opt.epoch, opt.n_epochs):\n","    for i, batch in enumerate(dataloader):\n","\n","        # Set model input\n","        real_A = Variable(batch[\"A\"].type(Tensor))\n","        real_B = Variable(batch[\"B\"].type(Tensor))\n","\n","        # Adversarial ground truths\n","        valid = Variable(Tensor(np.ones((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n","        fake = Variable(Tensor(np.zeros((real_A.size(0), *D_A.output_shape))), requires_grad=False)\n","\n","        # ------------------\n","        #  Train Generators\n","        # ------------------\n","\n","        G_AB.train()\n","        G_BA.train()\n","\n","        optimizer_G.zero_grad()\n","\n","        # Identity loss\n","        loss_id_A = criterion_identity(G_BA(real_A), real_A)\n","        loss_id_B = criterion_identity(G_AB(real_B), real_B)\n","\n","        loss_identity = (loss_id_A + loss_id_B) / 2\n","\n","        # GAN loss\n","        fake_B = G_AB(real_A)\n","        loss_GAN_AB = criterion_GAN(D_B(fake_B), valid)\n","        fake_A = G_BA(real_B)\n","        loss_GAN_BA = criterion_GAN(D_A(fake_A), valid)\n","\n","        loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n","\n","        # Cycle loss\n","        recov_A = G_BA(fake_B)\n","        loss_cycle_A = criterion_cycle(recov_A, real_A)\n","        recov_B = G_AB(fake_A)\n","        loss_cycle_B = criterion_cycle(recov_B, real_B)\n","\n","        loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n","\n","        # Total loss\n","        loss_G = loss_GAN + opt.lambda_cyc * loss_cycle + opt.lambda_id * loss_identity\n","\n","        loss_G.backward()\n","        optimizer_G.step()\n","\n","        # -----------------------\n","        #  Train Discriminator A\n","        # -----------------------\n","\n","        optimizer_D_A.zero_grad()\n","\n","        # Real loss\n","        loss_real = criterion_GAN(D_A(real_A), valid)\n","        # Fake loss (on batch of previously generated samples)\n","        fake_A_ = fake_A_buffer.push_and_pop(fake_A)\n","        loss_fake = criterion_GAN(D_A(fake_A_.detach()), fake)\n","        # Total loss\n","        loss_D_A = (loss_real + loss_fake) / 2\n","\n","        loss_D_A.backward()\n","        optimizer_D_A.step()\n","\n","        # -----------------------\n","        #  Train Discriminator B\n","        # -----------------------\n","\n","        optimizer_D_B.zero_grad()\n","\n","        # Real loss\n","        loss_real = criterion_GAN(D_B(real_B), valid)\n","        # Fake loss (on batch of previously generated samples)\n","        fake_B_ = fake_B_buffer.push_and_pop(fake_B)\n","        loss_fake = criterion_GAN(D_B(fake_B_.detach()), fake)\n","        # Total loss\n","        loss_D_B = (loss_real + loss_fake) / 2\n","\n","        loss_D_B.backward()\n","        optimizer_D_B.step()\n","\n","        loss_D = (loss_D_A + loss_D_B) / 2\n","\n","        # --------------\n","        #  Log Progress\n","        # --------------\n","\n","        # Determine approximate time left\n","        batches_done = epoch * len(dataloader) + i\n","        batches_left = opt.n_epochs * len(dataloader) - batches_done\n","        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n","        prev_time = time.time()\n","\n","        # Print log\n","        sys.stdout.write(\n","            \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n","            % (\n","                epoch,\n","                opt.n_epochs,\n","                i,\n","                len(dataloader),\n","                loss_D.item(),\n","                loss_G.item(),\n","                loss_GAN.item(),\n","                loss_cycle.item(),\n","                loss_identity.item(),\n","                time_left,\n","            )\n","        )\n","\n","        # If at sample interval save image\n","        if batches_done % opt.sample_interval == 0:\n","            sample_images(batches_done)\n","\n","    # Update learning rates\n","    lr_scheduler_G.step()\n","    lr_scheduler_D_A.step()\n","    lr_scheduler_D_B.step()\n","\n","    if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n","        # Save model checkpoints\n","        torch.save(G_AB.state_dict(), \"saved_models/%s/G_AB_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(G_BA.state_dict(), \"saved_models/%s/G_BA_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(D_A.state_dict(), \"saved_models/%s/D_A_%d.pth\" % (opt.dataset_name, epoch))\n","        torch.save(D_B.state_dict(), \"saved_models/%s/D_B_%d.pth\" % (opt.dataset_name, epoch))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[Epoch 2/3] [Batch 1018/1019] [D loss: 0.171700] [G loss: 3.383340, adv: 0.388138, cycle: 0.191623, identity: 0.215795] ETA: 0:00:00.200536"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tm_6oLduI89Y","executionInfo":{"status":"aborted","timestamp":1603099147140,"user_tz":-540,"elapsed":42502,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":[""],"execution_count":null,"outputs":[]}]}