{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11_stargan.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1e4NU6E85MVwnQm_zmx5ctEP7ZKq8iOfr","authorship_tag":"ABX9TyMRjrOKg5ykVlGeQpo/DDUo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"hdXTZWxdRlr4"},"source":["## StarGAN PyTorch実装を学ぶ\n","- Reference\n","  - https://github.com/eriklindernoren/PyTorch-GAN/tree/master/implementations/stargan  \n"]},{"cell_type":"code","metadata":{"id":"wNzTRQlrRdQv","executionInfo":{"status":"ok","timestamp":1604435277198,"user_tz":-540,"elapsed":955,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import os\n","import sys\n","import datetime\n","import time\n","import numpy as np\n","import pandas as pd\n","import itertools"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcuP0KtLR1sZ","executionInfo":{"status":"ok","timestamp":1604435281662,"user_tz":-540,"elapsed":5413,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import torchvision.transforms as transforms\n","from torchvision.utils import save_image"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-Frrihw_qCD","executionInfo":{"status":"ok","timestamp":1604435281663,"user_tz":-540,"elapsed":5409,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","import torch.autograd as autograd"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxFYcNcZ_u63","executionInfo":{"status":"ok","timestamp":1604435281664,"user_tz":-540,"elapsed":5405,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for model\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cymjIFCBWngT","executionInfo":{"status":"ok","timestamp":1604435281664,"user_tz":-540,"elapsed":5399,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for datasets\n","import glob\n","import random\n","#import os\n","#import numpy as np\n","\n","from torch.utils.data import Dataset\n","from PIL import Image"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYW7Q1oD_xr5","executionInfo":{"status":"ok","timestamp":1604435281665,"user_tz":-540,"elapsed":5394,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"59d06991-ef21-496a-a247-b276ba54961a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.__version__"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.6.0+cu101'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"lJaCA6PT_0JC","executionInfo":{"status":"ok","timestamp":1604435281666,"user_tz":-540,"elapsed":5389,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/project/ML/pytorch-gan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '11_out')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I4pzsl1AugF","executionInfo":{"status":"ok","timestamp":1604435282760,"user_tz":-540,"elapsed":6478,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1bxrWFV4A9cn","executionInfo":{"status":"ok","timestamp":1604435282761,"user_tz":-540,"elapsed":6476,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["cuda = True if torch.cuda.is_available() else False"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8bfdAxdXmeA","executionInfo":{"status":"ok","timestamp":1604435282761,"user_tz":-540,"elapsed":6472,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["##############################\n","#           RESNET\n","##############################\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","\n","        conv_block = [\n","            nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True),\n","        ]\n","\n","        self.conv_block = nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)\n","\n","\n","class GeneratorResNet(nn.Module):\n","    def __init__(self, img_shape=(3, 128, 128), res_blocks=9, c_dim=5):\n","        super(GeneratorResNet, self).__init__()\n","        channels, img_size, _ = img_shape\n","\n","        # Initial convolution block\n","        model = [\n","            nn.Conv2d(channels + c_dim, 64, 7, stride=1, padding=3, bias=False),\n","            nn.InstanceNorm2d(64, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True),\n","        ]\n","\n","        # Downsampling\n","        curr_dim = 64\n","        for _ in range(2):\n","            model += [\n","                nn.Conv2d(curr_dim, curr_dim * 2, 4, stride=2, padding=1, bias=False),\n","                nn.InstanceNorm2d(curr_dim * 2, affine=True, track_running_stats=True),\n","                nn.ReLU(inplace=True),\n","            ]\n","            curr_dim *= 2\n","\n","        # Residual blocks\n","        for _ in range(res_blocks):\n","            model += [ResidualBlock(curr_dim)]\n","\n","        # Upsampling\n","        for _ in range(2):\n","            model += [\n","                nn.ConvTranspose2d(curr_dim, curr_dim // 2, 4, stride=2, padding=1, bias=False),\n","                nn.InstanceNorm2d(curr_dim // 2, affine=True, track_running_stats=True),\n","                nn.ReLU(inplace=True),\n","            ]\n","            curr_dim = curr_dim // 2\n","\n","        # Output layer\n","        model += [nn.Conv2d(curr_dim, channels, 7, stride=1, padding=3), nn.Tanh()]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x, c):\n","        c = c.view(c.size(0), c.size(1), 1, 1)\n","        c = c.repeat(1, 1, x.size(2), x.size(3))\n","        x = torch.cat((x, c), 1)\n","        return self.model(x)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHFH9tmsChqv","executionInfo":{"status":"ok","timestamp":1604435282762,"user_tz":-540,"elapsed":6469,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["##############################\n","#        Discriminator\n","##############################\n","class Discriminator(nn.Module):\n","    def __init__(self, img_shape=(3, 128, 128), c_dim=5, n_strided=6):\n","        super(Discriminator, self).__init__()\n","        channels, img_size, _ = img_shape\n","\n","        def discriminator_block(in_filters, out_filters):\n","            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n","            layers = [\n","                nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1),\n","                nn.LeakyReLU(0.01)\n","            ]\n","            return layers\n","\n","        layers = discriminator_block(channels, 64)\n","        curr_dim = 64\n","        for _ in range(n_strided - 1):\n","            layers.extend(discriminator_block(curr_dim, curr_dim * 2))\n","            curr_dim *= 2\n","\n","        self.model = nn.Sequential(*layers)\n","\n","        # Output 1: PatchGAN\n","        self.out1 = nn.Conv2d(curr_dim, 1, 3, padding=1, bias=False)\n","\n","        # Output 2: Class prediction\n","        kernel_size = img_size // 2 ** n_strided\n","        self.out2 = nn.Conv2d(curr_dim, c_dim, kernel_size, bias=False)\n","\n","    def forward(self, img):\n","        feature_repr = self.model(img)\n","        out_adv = self.out1(feature_repr)\n","        out_cls = self.out2(feature_repr)\n","        return out_adv, out_cls.view(out_cls.size(0), -1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OuW8T06bf8g","executionInfo":{"status":"ok","timestamp":1604435282763,"user_tz":-540,"elapsed":6466,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CelebADataset(Dataset):\n","    def __init__(self, root, transforms_=None, mode=\"train\", attributes=None):\n","        self.transform = transforms.Compose(transforms_)\n","\n","        self.selected_attrs = attributes\n","        self.files = sorted(glob.glob(\"%s/*.jpg\" % root))\n","        #self.files = self.files[:-2000] if mode == \"train\" else self.files[-2000:]\n","        self.files = self.files[:-300] if mode == \"train\" else self.files[-300:]\n","        self.label_path = glob.glob(\"%s/*.txt\" % root)[0]\n","        self.annotations = self.get_annotations()\n","\n","    def get_annotations(self):\n","        \"\"\"Extracts annotations for CelebA\"\"\"\n","        annotations = {}\n","        lines = [line.rstrip() for line in open(self.label_path, \"r\")]\n","        self.label_names = lines[1].split()\n","        for _, line in enumerate(lines[2:]):\n","            filename, *values = line.split()\n","            labels = []\n","            for attr in self.selected_attrs:\n","                idx = self.label_names.index(attr)\n","                labels.append(1 * (values[idx] == \"1\"))\n","            annotations[filename] = labels\n","        return annotations\n","\n","    def __getitem__(self, index):\n","        filepath = self.files[index % len(self.files)]\n","        filename = filepath.split(\"/\")[-1]\n","        img = self.transform(Image.open(filepath))\n","        label = self.annotations[filename]\n","        label = torch.FloatTensor(np.array(label))\n","\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.files)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvDyQsQjHZbS","executionInfo":{"status":"ok","timestamp":1604435282763,"user_tz":-540,"elapsed":6462,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class Option:\n","    def __init__(self):\n","        self.epoch = 0\n","        #self.n_epochs = 200\n","        self.n_epochs = 5\n","        #self.dataset_name = \"img_align_celeba\"\n","        self.dataset_name = \"celeba\"\n","        self.batch_size = 16\n","        self.lr = 0.0002\n","        self.b1 = 0.5\n","        self.b2 = 0.999\n","        self.decay_epoch = 100\n","        self.n_cpu = 8\n","        self.img_height = 128\n","        self.img_width = 128\n","        self.channels = 3\n","        self.sample_interval = 400\n","        self.checkpoint_interval = -1\n","        self.residual_blocks = 6\n","        self.selected_attrs = [\"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\", \"Male\", \"Young\"]\n","        self.n_critic = 5\n","\n","opt = Option()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ic97OtIOEVGR","executionInfo":{"status":"ok","timestamp":1604435291591,"user_tz":-540,"elapsed":15286,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# Configure dataloaders\n","IMG_ROOT_PATH = os.path.join(DATA_DIR_PATH, opt.dataset_name)\n","\n","train_transforms = [\n","    transforms.Resize(int(1.12 * opt.img_height), Image.BICUBIC),\n","    transforms.RandomCrop(opt.img_height),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","]\n","\n","dataloader = DataLoader(\n","    CelebADataset(\n","        IMG_ROOT_PATH, transforms_=train_transforms, mode=\"train\", attributes=opt.selected_attrs\n","    ),\n","    batch_size=opt.batch_size,\n","    shuffle=True,\n","    num_workers=opt.n_cpu,\n",")\n","\n","val_transforms = [\n","    transforms.Resize((opt.img_height, opt.img_width), Image.BICUBIC),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","]\n","\n","val_dataloader = DataLoader(\n","    CelebADataset(\n","        IMG_ROOT_PATH, transforms_=val_transforms, mode=\"val\", attributes=opt.selected_attrs\n","    ),\n","    batch_size=10,\n","    shuffle=True,\n","    num_workers=1,\n",")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uaa2jTrAOU7n","executionInfo":{"status":"ok","timestamp":1604435413783,"user_tz":-540,"elapsed":675,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","\n","def criterion_cls(logit, target):\n","    return F.binary_cross_entropy_with_logits(logit, target, size_average=False) / logit.size(0)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCsUq86WSRg4","executionInfo":{"status":"ok","timestamp":1604435655942,"user_tz":-540,"elapsed":1211,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class StarGAN:\n","    def __init__(self, options, data_loader, val_data_loader, c_dim, img_shape, residual_blocks=9):\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'batche_i',\n","            'loss_D_adv', 'loss_D_cls',\n","            'loss_G', 'loss_G_adv', 'loss_G_cls', 'loss_G_recy'\n","            'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.G_name = 'generator'\n","        self.train_cnt = 0\n","\n","        self.opt = options\n","        self.data_loader = data_loader\n","        self.val_data_loader = val_data_loader\n","        self.c_dim = c_dim\n","        self.img_shape = img_shape\n","        self.residual_blocks = residual_blocks\n","\n","        # Loss functions\n","        self.criterion_cycle = torch.nn.L1Loss()\n","\n","        # Loss weights\n","        self.lambda_cls = 1\n","        self.lambda_rec = 10\n","        self.lambda_gp = 10\n","\n","        # Initialize generator and discriminator\n","        self.generator = GeneratorResNet(img_shape=self.img_shape, res_blocks=self.residual_blocks, c_dim=self.c_dim)\n","        self.discriminator = Discriminator(img_shape=self.img_shape, c_dim=self.c_dim)\n","\n","        if cuda:\n","            self.generator = self.generator.cuda()\n","            self.discriminator = self.discriminator.cuda()\n","            self.criterion_cycle.cuda()\n","\n","        # if opt.epoch != 0:\n","        #     # Load pretrained models\n","        #     G_AB.load_state_dict(torch.load(\"saved_models/%s/G_AB_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     G_BA.load_state_dict(torch.load(\"saved_models/%s/G_BA_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     D_A.load_state_dict(torch.load(\"saved_models/%s/D_A_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     D_B.load_state_dict(torch.load(\"saved_models/%s/D_B_%d.pth\" % (self.dataset_name, self.epoch)))\n","        # if opt.epoch != 0:\n","        #     # Load pretrained models\n","        #     generator.load_state_dict(torch.load(\"saved_models/generator_%d.pth\" % opt.epoch))\n","        #     discriminator.load_state_dict(torch.load(\"saved_models/discriminator_%d.pth\" % opt.epoch))\n","        # else:\n","        self.generator.apply(weights_init_normal)\n","        self.discriminator.apply(weights_init_normal)\n","\n","        # Optimizers\n","        self.optimizer_G = torch.optim.Adam(\n","            self.generator.parameters(), lr=self.opt.lr, betas=(self.opt.b1, self.opt.b2))\n","        self.optimizer_D = torch.optim.Adam(\n","            self.discriminator.parameters(), lr=self.opt.lr, betas=(self.opt.b1, self.opt.b2))\n","\n","        self.Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","\n","        # for sample_images\n","        self.label_changes = [\n","            ((0, 1), (1, 0), (2, 0)),  # Set to black hair\n","            ((0, 0), (1, 1), (2, 0)),  # Set to blonde hair\n","            ((0, 0), (1, 0), (2, 1)),  # Set to brown hair\n","            ((3, -1),),  # Flip gender\n","            ((4, -1),),  # Age flip\n","        ]\n","\n","    def train(self, n_epochs, n_critic, sample_interval=-1):\n","        epoch = 0\n","\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        step_cnt = 1\n","\n","        for epoch_i in range(epoch+1, n_epochs+1):\n","\n","            for batch_i, (imgs, labels) in enumerate(self.data_loader, 1):\n","                # Model inputs\n","                imgs = Variable(imgs.type(self.Tensor))\n","                labels = Variable(labels.type(self.Tensor))\n","\n","                # Sample labels as generator inputs\n","                sampled_c = Variable(self.Tensor(np.random.randint(0, 2, (imgs.size(0), self.c_dim))))\n","\n","                # Generate fake batch of images\n","                fake_imgs = self.generator(imgs, sampled_c)\n","\n","                # ---------------------\n","                #  Train Discriminator\n","                # ---------------------\n","                self.optimizer_D.zero_grad()\n","\n","                # Real images\n","                real_validity, pred_cls = self.discriminator(imgs)\n","                # Fake images\n","                fake_validity, _ = self.discriminator(fake_imgs.detach())\n","                # Gradient penalty\n","                gradient_penalty = self.compute_gradient_penalty(self.discriminator, imgs.data, fake_imgs.data)\n","                # Adversarial loss\n","                loss_D_adv = -torch.mean(real_validity) + torch.mean(fake_validity) + self.lambda_gp * gradient_penalty\n","                # Classification loss\n","                loss_D_cls = criterion_cls(pred_cls, labels)\n","                # Total loss\n","                loss_D = loss_D_adv + self.lambda_cls * loss_D_cls\n","\n","                loss_D.backward()\n","                self.optimizer_D.step()\n","\n","                self.optimizer_G.zero_grad()\n","\n","                # Every n_critic times update generator\n","                if batch_i % n_critic == 0:\n","\n","                    # -----------------\n","                    #  Train Generator\n","                    # -----------------\n","\n","                    # Translate and reconstruct image\n","                    gen_imgs = self.generator(imgs, sampled_c)\n","                    recov_imgs = self.generator(gen_imgs, labels)\n","                    # Discriminator evaluates translated image\n","                    fake_validity, pred_cls = self.discriminator(gen_imgs)\n","                    # Adversarial loss\n","                    loss_G_adv = -torch.mean(fake_validity)\n","                    # Classification loss\n","                    loss_G_cls = criterion_cls(pred_cls, sampled_c)\n","                    # Reconstruction loss\n","                    loss_G_rec = self.criterion_cycle(recov_imgs, imgs)\n","                    # Total loss\n","                    loss_G = loss_G_adv + self.lambda_cls * loss_G_cls + self.lambda_rec * loss_G_rec\n","\n","                    loss_G.backward()\n","                    self.optimizer_G.step()\n","\n","                    # --------------\n","                    #  Log Progress\n","                    # --------------\n","\n","                    # Determine approximate time left\n","                    batches_done = epoch * len(dataloader) + batch_i\n","                    batches_left = opt.n_epochs * len(dataloader) - batches_done\n","                    time_left = datetime.timedelta(seconds=batches_left * (time.time() - start_time) / (batches_done + 1))\n","\n","                    elapsed_time = datetime.datetime.now() - start_time\n","\n","                    # Print log\n","                    sys.stdout.write(\n","                        \"\\r[Epoch %d/%d] [Batch %d/%d] [D adv: %f, aux: %f] [G loss: %f, adv: %f, aux: %f, cycle: %f] ETA: %s\"\n","                        % (\n","                            epoch,\n","                            opt.n_epochs,\n","                            batch_i,\n","                            len(dataloader),\n","                            loss_D_adv.item(),\n","                            loss_D_cls.item(),\n","                            loss_G.item(),\n","                            loss_G_adv.item(),\n","                            loss_G_cls.item(),\n","                            loss_G_rec.item(),\n","                            time_left,\n","                        )\n","                    )\n","\n","                    self.history = self.history.append({\n","                        'epoch':   epoch_i,\n","                        'batch_i': batch_i,\n","                        'loss_D_adv': loss_D_adv.item(),\n","                        'loss_D_cls': loss_D_cls.item(),\n","                        'loss_G':     loss_G.item(),\n","                        'loss_G_adv': loss_G_adv.item(),\n","                        'loss_G_cls': loss_G_cls.item(),\n","                        'loss_G_rec': loss_G_rec.item(),\n","                        'elapsed_time': elapsed_time\n","                    }, ignore_index=True)\n","\n","                    # If at sample interval sample and save image\n","                    # if batches_done % opt.sample_interval == 0:\n","                    #     sample_images(batches_done)\n","                    if sample_interval > 0 and batches_done % sample_interval == 0:\n","                        self.sample_images(epoch, batch_i)\n","\n","                # if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                #     self.sample_images(epoch, batch_i)\n","\n","                step_cnt += 1\n","\n","            # if opt.checkpoint_interval != -1 and epoch % opt.checkpoint_interval == 0:\n","            #     # Save model checkpoints\n","            #     torch.save(generator.state_dict(), \"saved_models/generator_%d.pth\" % epoch)\n","            #     torch.save(discriminator.state_dict(), \"saved_models/discriminator_%d.pth\" % epoch)\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    def compute_gradient_penalty(self, D, real_samples, fake_samples):\n","        \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n","        # Random weight term for interpolation between real and fake samples\n","        alpha = self.Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n","        # Get random interpolation between real and fake samples\n","        interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n","        d_interpolates, _ = D(interpolates)\n","        fake = Variable(self.Tensor(np.ones(d_interpolates.shape)), requires_grad=False)\n","\n","        # Get gradient w.r.t. interpolates\n","        gradients = autograd.grad(\n","            outputs=d_interpolates,\n","            inputs=interpolates,\n","            grad_outputs=fake,\n","            create_graph=True,\n","            retain_graph=True,\n","            only_inputs=True,\n","        )[0]\n","        gradients = gradients.view(gradients.size(0), -1)\n","        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","\n","        return gradient_penalty\n","\n","    def sample_images(self, epoch, batch_i, n_row=5):\n","        \"\"\"Saves a generated sample of domain translations\"\"\"\n","        val_imgs, val_labels = next(iter(val_dataloader))\n","        val_imgs = Variable(val_imgs.type(self.Tensor))\n","        val_labels = Variable(val_labels.type(self.Tensor))\n","\n","        img_samples = None\n","\n","        for i in range(10):\n","            img, label = val_imgs[i], val_labels[i]\n","\n","            # Repeat for number of label changes\n","            imgs = img.repeat(self.c_dim, 1, 1, 1)\n","            labels = label.repeat(self.c_dim, 1)\n","\n","            # Make changes to labels\n","            for sample_i, changes in enumerate(self.label_changes):\n","                for col, val in changes:\n","                    labels[sample_i, col] = 1 - labels[sample_i, col] if val == -1 else val\n","\n","            # Generate translations\n","            gen_imgs = self.generator(imgs, labels)\n","\n","            # Concatenate images by width\n","            gen_imgs = torch.cat([x for x in gen_imgs.data], -1)\n","            img_sample = torch.cat((img.data, gen_imgs), -1)\n","\n","            # Add as row to generated samples\n","            img_samples = img_sample if img_samples is None else torch.cat((img_samples, img_sample), -2)\n","\n","        file_name = os.path.join(self.img_save_dir, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        save_image(img_samples.view(1, *img_samples.shape), file_name, normalize=True)\n","\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['loss_G']\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_state_dict(self.generator, self.G_name, file_suffix)\n","\n","    def save_state_dict(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_model_file_name(model_name, file_suffix))\n","        torch.save(model.state_dict(), file_path)\n","        print('Model saved.', model_name)\n","\n","    def _create_model_file_name(self, model_name, suffix=None):\n","        processor = 'gpu' if cuda else 'cpu'\n","\n","        if suffix:\n","            return '{}_{}_{}.pth'.format(model_name, processor, suffix)\n","        else:\n","            return '{}_{}.pth'.format(model_name, processor)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0oP_OUFIDYJ","executionInfo":{"status":"error","timestamp":1604435664305,"user_tz":-540,"elapsed":7624,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"993b6cf8-1531-4bbe-f9b2-f64c5d7a1ad0","colab":{"base_uri":"https://localhost:8080/","height":382}},"source":["n_epochs = 1\n","sample_interval = 10\n","c_dim = len(opt.selected_attrs)\n","img_shape = (opt.channels, opt.img_height, opt.img_width)\n","\n","gan = StarGAN(opt, dataloader, val_dataloader, c_dim, img_shape)\n","gan.train(n_epochs, opt.n_critic, sample_interval)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["2020-11-03T20:34:17.450157 Start 1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-0ea038c0514b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStarGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-27-5d8b69cbc406>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, n_epochs, n_critic, sample_interval)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mbatches_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                     \u001b[0mbatches_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatches_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                     \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatches_left\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatches_done\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'datetime.datetime'"]}]},{"cell_type":"code","metadata":{"id":"neqHPmwJoz9H","executionInfo":{"status":"aborted","timestamp":1604435322787,"user_tz":-540,"elapsed":46459,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#gan.plot_hisotry()\n","\n","#gan.save_models()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P95nomvfwHrb","executionInfo":{"status":"aborted","timestamp":1604435322788,"user_tz":-540,"elapsed":46458,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":[""],"execution_count":null,"outputs":[]}]}