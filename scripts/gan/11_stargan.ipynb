{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"11_stargan.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1e4NU6E85MVwnQm_zmx5ctEP7ZKq8iOfr","authorship_tag":"ABX9TyP0nsnQbvidyoDD+jBOldZJ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hdXTZWxdRlr4"},"source":["## StarGAN PyTorch実装を学ぶ\n","- Reference\n","  - https://github.com/eriklindernoren/PyTorch-GAN/tree/master/implementations/stargan  \n"]},{"cell_type":"code","metadata":{"id":"wNzTRQlrRdQv","executionInfo":{"status":"ok","timestamp":1604255222143,"user_tz":-540,"elapsed":674,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import os\n","import sys\n","import datetime\n","import time\n","import numpy as np\n","import pandas as pd\n","import itertools"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"HcuP0KtLR1sZ","executionInfo":{"status":"ok","timestamp":1604255244421,"user_tz":-540,"elapsed":3280,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["import torchvision.transforms as transforms\n","from torchvision.utils import save_image"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-Frrihw_qCD","executionInfo":{"status":"ok","timestamp":1604255249620,"user_tz":-540,"elapsed":546,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","import torch.autograd as autograd"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"cxFYcNcZ_u63","executionInfo":{"status":"ok","timestamp":1604255257525,"user_tz":-540,"elapsed":535,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for model\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cymjIFCBWngT","executionInfo":{"status":"ok","timestamp":1604255284810,"user_tz":-540,"elapsed":614,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# for datasets\n","import glob\n","import random\n","#import os\n","#import numpy as np\n","\n","from torch.utils.data import Dataset\n","from PIL import Image"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYW7Q1oD_xr5","executionInfo":{"status":"ok","timestamp":1604255287700,"user_tz":-540,"elapsed":562,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}},"outputId":"e4ece431-2287-4cad-faf4-41e3c2e88790","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["torch.__version__"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'1.6.0+cu101'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"lJaCA6PT_0JC","executionInfo":{"status":"ok","timestamp":1604255306016,"user_tz":-540,"elapsed":515,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["DATA_DIR_PATH = '/content/drive/My Drive/project/ML/pytorch-gan/data'\n","\n","OUTPUT_DIR_PATH = os.path.join(DATA_DIR_PATH, '11_out')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3I4pzsl1AugF","executionInfo":{"status":"ok","timestamp":1604255307848,"user_tz":-540,"elapsed":1225,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'images'), exist_ok=True)\n","os.makedirs(os.path.join(OUTPUT_DIR_PATH, 'saved_models'), exist_ok=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"1bxrWFV4A9cn","executionInfo":{"status":"ok","timestamp":1604255311148,"user_tz":-540,"elapsed":678,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["cuda = True if torch.cuda.is_available() else False"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"E8bfdAxdXmeA","executionInfo":{"status":"ok","timestamp":1604255421682,"user_tz":-540,"elapsed":556,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["##############################\n","#           RESNET\n","##############################\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_features):\n","        super(ResidualBlock, self).__init__()\n","\n","        conv_block = [\n","            nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(in_features, in_features, 3, stride=1, padding=1, bias=False),\n","            nn.InstanceNorm2d(in_features, affine=True, track_running_stats=True),\n","        ]\n","\n","        self.conv_block = nn.Sequential(*conv_block)\n","\n","    def forward(self, x):\n","        return x + self.conv_block(x)\n","\n","\n","class GeneratorResNet(nn.Module):\n","    def __init__(self, img_shape=(3, 128, 128), res_blocks=9, c_dim=5):\n","        super(GeneratorResNet, self).__init__()\n","        channels, img_size, _ = img_shape\n","\n","        # Initial convolution block\n","        model = [\n","            nn.Conv2d(channels + c_dim, 64, 7, stride=1, padding=3, bias=False),\n","            nn.InstanceNorm2d(64, affine=True, track_running_stats=True),\n","            nn.ReLU(inplace=True),\n","        ]\n","\n","        # Downsampling\n","        curr_dim = 64\n","        for _ in range(2):\n","            model += [\n","                nn.Conv2d(curr_dim, curr_dim * 2, 4, stride=2, padding=1, bias=False),\n","                nn.InstanceNorm2d(curr_dim * 2, affine=True, track_running_stats=True),\n","                nn.ReLU(inplace=True),\n","            ]\n","            curr_dim *= 2\n","\n","        # Residual blocks\n","        for _ in range(res_blocks):\n","            model += [ResidualBlock(curr_dim)]\n","\n","        # Upsampling\n","        for _ in range(2):\n","            model += [\n","                nn.ConvTranspose2d(curr_dim, curr_dim // 2, 4, stride=2, padding=1, bias=False),\n","                nn.InstanceNorm2d(curr_dim // 2, affine=True, track_running_stats=True),\n","                nn.ReLU(inplace=True),\n","            ]\n","            curr_dim = curr_dim // 2\n","\n","        # Output layer\n","        model += [nn.Conv2d(curr_dim, channels, 7, stride=1, padding=3), nn.Tanh()]\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x, c):\n","        c = c.view(c.size(0), c.size(1), 1, 1)\n","        c = c.repeat(1, 1, x.size(2), x.size(3))\n","        x = torch.cat((x, c), 1)\n","        return self.model(x)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHFH9tmsChqv","executionInfo":{"status":"ok","timestamp":1604255481562,"user_tz":-540,"elapsed":519,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["##############################\n","#        Discriminator\n","##############################\n","class Discriminator(nn.Module):\n","    def __init__(self, img_shape=(3, 128, 128), c_dim=5, n_strided=6):\n","        super(Discriminator, self).__init__()\n","        channels, img_size, _ = img_shape\n","\n","        def discriminator_block(in_filters, out_filters):\n","            \"\"\"Returns downsampling layers of each discriminator block\"\"\"\n","            layers = [\n","                nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1),\n","                nn.LeakyReLU(0.01)\n","            ]\n","            return layers\n","\n","        layers = discriminator_block(channels, 64)\n","        curr_dim = 64\n","        for _ in range(n_strided - 1):\n","            layers.extend(discriminator_block(curr_dim, curr_dim * 2))\n","            curr_dim *= 2\n","\n","        self.model = nn.Sequential(*layers)\n","\n","        # Output 1: PatchGAN\n","        self.out1 = nn.Conv2d(curr_dim, 1, 3, padding=1, bias=False)\n","\n","        # Output 2: Class prediction\n","        kernel_size = img_size // 2 ** n_strided\n","        self.out2 = nn.Conv2d(curr_dim, c_dim, kernel_size, bias=False)\n","\n","    def forward(self, img):\n","        feature_repr = self.model(img)\n","        out_adv = self.out1(feature_repr)\n","        out_cls = self.out2(feature_repr)\n","        return out_adv, out_cls.view(out_cls.size(0), -1)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"5OuW8T06bf8g","executionInfo":{"status":"ok","timestamp":1604256285771,"user_tz":-540,"elapsed":565,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class CelebADataset(Dataset):\n","    def __init__(self, root, transforms_=None, mode=\"train\", attributes=None):\n","        self.transform = transforms.Compose(transforms_)\n","\n","        self.selected_attrs = attributes\n","        self.files = sorted(glob.glob(\"%s/*.jpg\" % root))\n","        #self.files = self.files[:-2000] if mode == \"train\" else self.files[-2000:]\n","        self.files = self.files[:-300] if mode == \"train\" else self.files[-300:]\n","        self.label_path = glob.glob(\"%s/*.txt\" % root)[0]\n","        self.annotations = self.get_annotations()\n","\n","    def get_annotations(self):\n","        \"\"\"Extracts annotations for CelebA\"\"\"\n","        annotations = {}\n","        lines = [line.rstrip() for line in open(self.label_path, \"r\")]\n","        self.label_names = lines[1].split()\n","        for _, line in enumerate(lines[2:]):\n","            filename, *values = line.split()\n","            labels = []\n","            for attr in self.selected_attrs:\n","                idx = self.label_names.index(attr)\n","                labels.append(1 * (values[idx] == \"1\"))\n","            annotations[filename] = labels\n","        return annotations\n","\n","    def __getitem__(self, index):\n","        filepath = self.files[index % len(self.files)]\n","        filename = filepath.split(\"/\")[-1]\n","        img = self.transform(Image.open(filepath))\n","        label = self.annotations[filename]\n","        label = torch.FloatTensor(np.array(label))\n","\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.files)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"LvDyQsQjHZbS","executionInfo":{"status":"ok","timestamp":1604256287779,"user_tz":-540,"elapsed":541,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["class Option:\n","    def __init__(self):\n","        self.epoch = 0\n","        #self.n_epochs = 200\n","        self.n_epochs = 5\n","        #self.dataset_name = \"img_align_celeba\"\n","        self.dataset_name = \"celeba\"\n","        self.batch_size = 16\n","        self.lr = 0.0002\n","        self.b1 = 0.5\n","        self.b2 = 0.999\n","        self.decay_epoch = 100\n","        self.n_cpu = 8\n","        self.img_height = 128\n","        self.img_width = 128\n","        self.channels = 3\n","        self.sample_interval = 400\n","        self.checkpoint_interval = -1\n","        self.residual_blocks = 6\n","        self.selected_attrs = [\"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\", \"Male\", \"Young\"]\n","        self.n_critic = 5\n","\n","opt = Option()"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"ic97OtIOEVGR","executionInfo":{"status":"ok","timestamp":1604256358819,"user_tz":-540,"elapsed":1071,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["# Configure dataloaders\n","IMG_ROOT_PATH = os.path.join(DATA_DIR_PATH, opt.dataset_name)\n","\n","train_transforms = [\n","    transforms.Resize(int(1.12 * opt.img_height), Image.BICUBIC),\n","    transforms.RandomCrop(opt.img_height),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","]\n","\n","dataloader = DataLoader(\n","    CelebADataset(\n","        IMG_ROOT_PATH, transforms_=train_transforms, mode=\"train\", attributes=opt.selected_attrs\n","    ),\n","    batch_size=opt.batch_size,\n","    shuffle=True,\n","    num_workers=opt.n_cpu,\n",")\n","\n","val_transforms = [\n","    transforms.Resize((opt.img_height, opt.img_width), Image.BICUBIC),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","]\n","\n","val_dataloader = DataLoader(\n","    CelebADataset(\n","        IMG_ROOT_PATH, transforms_=val_transforms, mode=\"val\", attributes=opt.selected_attrs\n","    ),\n","    batch_size=10,\n","    shuffle=True,\n","    num_workers=1,\n",")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uaa2jTrAOU7n","executionInfo":{"status":"ok","timestamp":1604258291687,"user_tz":-540,"elapsed":531,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","\n","def criterion_cls(logit, target):\n","    return F.binary_cross_entropy_with_logits(logit, target, size_average=False) / logit.size(0)\n","\n","\n","def compute_gradient_penalty(D, real_samples, fake_samples):\n","    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n","    # Random weight term for interpolation between real and fake samples\n","    alpha = Tensor(np.random.random((real_samples.size(0), 1, 1, 1)))\n","    # Get random interpolation between real and fake samples\n","    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n","    d_interpolates, _ = D(interpolates)\n","    fake = Variable(Tensor(np.ones(d_interpolates.shape)), requires_grad=False)\n","\n","    # Get gradient w.r.t. interpolates\n","    gradients = autograd.grad(\n","        outputs=d_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=fake,\n","        create_graph=True,\n","        retain_graph=True,\n","        only_inputs=True,\n","    )[0]\n","    gradients = gradients.view(gradients.size(0), -1)\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","\n","    return gradient_penalty"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCsUq86WSRg4"},"source":["class StarGAN:\n","    # TODO\n","    def __init__(self, options, data_loader, val_data_loader, c_dim, img_shape, residual_blocks=9):\n","        # TODO\n","        self.history = pd.DataFrame({}, columns=[\n","            'epoch', 'batche_i',\n","            'loss_D', 'loss_G', 'loss_GAN', 'loss_cycle', 'loss_identity'\n","            'elapsed_time'])\n","\n","        self.img_save_dir = os.path.join(OUTPUT_DIR_PATH, 'images')\n","        self.model_save_dir = os.path.join(OUTPUT_DIR_PATH, 'saved_models')\n","        self.G_name = 'generator'\n","        self.train_cnt = 0\n","\n","        self.opt = options\n","        self.data_loader = data_loader\n","        self.val_data_loader = val_data_loader\n","        self.c_dim = c_dim\n","        self.img_shape = img_shape\n","        self.residual_blocks = residual_blocks\n","\n","        # Loss functions\n","        self.criterion_cycle = torch.nn.L1Loss()\n","\n","        # Loss weights\n","        self.lambda_cls = 1\n","        self.lambda_rec = 10\n","        self.lambda_gp = 10\n","\n","        # Initialize generator and discriminator\n","        self.generator = GeneratorResNet(img_shape=self.img_shape, res_blocks=self..residual_blocks, c_dim=self.c_dim)\n","        self.discriminator = Discriminator(img_shape=self.img_shape, c_dim=self.c_dim)\n","\n","        if cuda:\n","            self.generator = self.generator.cuda()\n","            self.discriminator = self.discriminator.cuda()\n","            self.criterion_cycle.cuda()\n","\n","        # if opt.epoch != 0:\n","        #     # Load pretrained models\n","        #     G_AB.load_state_dict(torch.load(\"saved_models/%s/G_AB_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     G_BA.load_state_dict(torch.load(\"saved_models/%s/G_BA_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     D_A.load_state_dict(torch.load(\"saved_models/%s/D_A_%d.pth\" % (self.dataset_name, self.epoch)))\n","        #     D_B.load_state_dict(torch.load(\"saved_models/%s/D_B_%d.pth\" % (self.dataset_name, self.epoch)))\n","        # if opt.epoch != 0:\n","        #     # Load pretrained models\n","        #     generator.load_state_dict(torch.load(\"saved_models/generator_%d.pth\" % opt.epoch))\n","        #     discriminator.load_state_dict(torch.load(\"saved_models/discriminator_%d.pth\" % opt.epoch))\n","        # else:\n","        self.generator.apply(weights_init_normal)\n","        self.discriminator.apply(weights_init_normal)\n","\n","        # Optimizers\n","        self.optimizer_G = torch.optim.Adam(\n","            self.generator.parameters(), lr=self.opt.lr, betas=(self.opt.b1, self.opt.b2))\n","        self.optimizer_D = torch.optim.Adam(\n","            self.discriminator.parameters(), lr=self.opt.lr, betas=(self.opt.b1, self.opt.b2))\n","\n","        self.Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","\n","        # for sample_images\n","        self.label_changes = [\n","            ((0, 1), (1, 0), (2, 0)),  # Set to black hair\n","            ((0, 0), (1, 1), (2, 0)),  # Set to blonde hair\n","            ((0, 0), (1, 0), (2, 1)),  # Set to brown hair\n","            ((3, -1),),  # Flip gender\n","            ((4, -1),),  # Age flip\n","        ]\n","\n","    # TODO\n","    def train(self, n_epochs, decay_epoch, sample_interval=-1):\n","        epoch = 0\n","\n","        self.train_cnt += 1\n","\n","        print(datetime.datetime.now().isoformat(), 'Start', self.train_cnt)\n","\n","        start_time = datetime.datetime.now()\n","\n","        step_cnt = 1\n","\n","        # Learning rate update schedulers\n","        lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n","            self.optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n","        )\n","        lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n","            self.optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n","        )\n","        lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n","            self.optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step\n","        )\n","\n","        for epoch_i in range(epoch+1, n_epochs+1):\n","\n","            for batch_i, batch in enumerate(self.data_loader, 1):\n","                # Set model input\n","                real_A = Variable(batch[\"A\"].type(self.Tensor))\n","                real_B = Variable(batch[\"B\"].type(self.Tensor))\n","\n","                # Adversarial ground truths\n","                valid = Variable(self.Tensor(np.ones((real_A.size(0), *self.D_A.output_shape))), requires_grad=False)\n","                fake  = Variable(self.Tensor(np.zeros((real_A.size(0), *self.D_A.output_shape))), requires_grad=False)\n","\n","                # Train Generator\n","                self.G_AB.train()\n","                self.G_BA.train()\n","\n","                self.optimizer_G.zero_grad()\n","\n","                # Identity loss\n","                loss_id_A = self.criterion_identity(self.G_BA(real_A), real_A)\n","                loss_id_B = self.criterion_identity(self.G_AB(real_B), real_B)\n","\n","                loss_identity = (loss_id_A + loss_id_B) / 2\n","\n","                # GAN loss\n","                fake_B = self.G_AB(real_A)\n","                loss_GAN_AB = self.criterion_GAN(self.D_B(fake_B), valid)\n","                fake_A = self.G_BA(real_B)\n","                loss_GAN_BA = self.criterion_GAN(self.D_A(fake_A), valid)\n","\n","                loss_GAN = (loss_GAN_AB + loss_GAN_BA) / 2\n","\n","                # Cycle loss\n","                recov_A = self.G_BA(fake_B)\n","                loss_cycle_A = self.criterion_cycle(recov_A, real_A)\n","                recov_B = self.G_AB(fake_A)\n","                loss_cycle_B = self.criterion_cycle(recov_B, real_B)\n","\n","                loss_cycle = (loss_cycle_A + loss_cycle_B) / 2\n","\n","                # Total loss\n","                loss_G = loss_GAN + self.lambda_cyc * loss_cycle + self.lambda_id * loss_identity\n","\n","                loss_G.backward()\n","                self.optimizer_G.step()\n","\n","                # Train Discriminator A\n","                self.optimizer_D_A.zero_grad()\n","\n","                # Real loss\n","                loss_real = self.criterion_GAN(self.D_A(real_A), valid)\n","                # Fake loss (on batch of previously generated samples)\n","                fake_A_ = self.fake_A_buffer.push_and_pop(fake_A)\n","                loss_fake = self.criterion_GAN(self.D_A(fake_A_.detach()), fake)\n","                # Total loss\n","                loss_D_A = (loss_real + loss_fake) / 2\n","\n","                loss_D_A.backward()\n","                self.optimizer_D_A.step()\n","\n","                # Train Discriminator B\n","                self.optimizer_D_B.zero_grad()\n","\n","                # Real loss\n","                loss_real = self.criterion_GAN(self.D_B(real_B), valid)\n","                # Fake loss (on batch of previously generated samples)\n","                fake_B_ = self.fake_B_buffer.push_and_pop(fake_B)\n","                loss_fake = self.criterion_GAN(self.D_B(fake_B_.detach()), fake)\n","                # Total loss\n","                loss_D_B = (loss_real + loss_fake) / 2\n","\n","                loss_D_B.backward()\n","                self.optimizer_D_B.step()\n","\n","                loss_D = (loss_D_A + loss_D_B) / 2\n","\n","                # Log Progress\n","                batches_done = epoch_i * len(self.data_loader) + batch_i\n","                elapsed_time = datetime.datetime.now() - start_time\n","\n","                self.history = self.history.append({\n","                    'epoch': epoch_i,\n","                    'batch_i': batch_i,\n","                    'loss_D':loss_D.item(),\n","                    'loss_G': loss_G.item(),\n","                    'loss_GAN': loss_GAN.item(),\n","                    'loss_cycle': loss_cycle.item(),\n","                    'loss_identity': loss_identity.item(),\n","                    'elapsed_time': elapsed_time\n","                }, ignore_index=True)\n","\n","\n","                if sample_interval > 0 and step_cnt % sample_interval == 0:\n","                    print(\n","                        '[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] %s'\n","                        % (\n","                            epoch_i,\n","                            n_epochs,\n","                            batch_i,\n","                            len(self.data_loader),\n","                            loss_D.item(),\n","                            loss_G.item(),\n","                            loss_GAN.item(),\n","                            loss_cycle.item(),\n","                            loss_identity.item(),\n","                            elapsed_time\n","                        )\n","                    )\n","                    # sys.stdout.write(\n","                    #     \"\\r[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f, adv: %f, cycle: %f, identity: %f] ETA: %s\"\n","                    #     % (\n","                    #         epoch,\n","                    #         opt.n_epochs,\n","                    #         i,\n","                    #         len(dataloader),\n","                    #         loss_D.item(),\n","                    #         loss_G.item(),\n","                    #         loss_GAN.item(),\n","                    #         loss_cycle.item(),\n","                    #         loss_identity.item(),\n","                    #         time_left,\n","                    #     )\n","                    # )\n","\n","                    self.sample_images(epoch, batch_i)\n","\n","                step_cnt += 1\n","\n","            # Update learning rates\n","            lr_scheduler_G.step()\n","            lr_scheduler_D_A.step()\n","            lr_scheduler_D_B.step()\n","\n","        print(datetime.datetime.now().isoformat(), 'End')\n","\n","    #\n","    #def sample_images(batches_done):\n","    def sample_images(self, epoch, batch_i, n_row=5):\n","        \"\"\"Saves a generated sample of domain translations\"\"\"\n","        val_imgs, val_labels = next(iter(val_dataloader))\n","        val_imgs = Variable(val_imgs.type(self.Tensor))\n","        val_labels = Variable(val_labels.type(self.Tensor))\n","\n","        img_samples = None\n","\n","        for i in range(10):\n","            img, label = val_imgs[i], val_labels[i]\n","\n","            # Repeat for number of label changes\n","            imgs = img.repeat(self.c_dim, 1, 1, 1)\n","            labels = label.repeat(self.c_dim, 1)\n","\n","            # Make changes to labels\n","            for sample_i, changes in enumerate(self.label_changes):\n","                for col, val in changes:\n","                    labels[sample_i, col] = 1 - labels[sample_i, col] if val == -1 else val\n","\n","            # Generate translations\n","            gen_imgs = self.generator(imgs, labels)\n","\n","            # Concatenate images by width\n","            gen_imgs = torch.cat([x for x in gen_imgs.data], -1)\n","            img_sample = torch.cat((img.data, gen_imgs), -1)\n","\n","            # Add as row to generated samples\n","            img_samples = img_sample if img_samples is None else torch.cat((img_samples, img_sample), -2)\n","\n","        file_name = os.path.join(self.img_save_dir, '{}_{}_{}.png'.format(self.train_cnt, epoch, batch_i))\n","        save_image(img_samples.view(1, *img_samples.shape), file_name, normalize=True)\n","\n","    # TODO\n","    def plot_hisotry(self, columns=[]):\n","        if len(columns) == 0:\n","            columns = ['loss_D', 'loss_G']\n","        self.history[columns].plot()\n","\n","    def save_models(self, file_suffix=None):\n","        self.save_state_dict(self.generator, self.G_name, file_suffix)\n","\n","    def save_state_dict(self, model, model_name, file_suffix=None):\n","        file_path = os.path.join(self.model_save_dir, self._create_model_file_name(model_name, file_suffix))\n","        torch.save(model.state_dict(), file_path)\n","        print('Model saved.', model_name)\n","\n","    def _create_model_file_name(self, model_name, suffix=None):\n","        processor = 'gpu' if cuda else 'cpu'\n","\n","        if suffix:\n","            return '{}_{}_{}.pth'.format(model_name, processor, suffix)\n","        else:\n","            return '{}_{}.pth'.format(model_name, processor)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0oP_OUFIDYJ","executionInfo":{"status":"ok","timestamp":1604258965967,"user_tz":-540,"elapsed":551,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#n_epochs = 1\n","#decay_epoch = 0\n","#sample_interval = 50\n","\n","#gan = StarGAN(dataloader, val_dataloader, input_shape)\n","#gan.train(n_epochs, decay_epoch, sample_interval)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"neqHPmwJoz9H","executionInfo":{"status":"ok","timestamp":1604258972645,"user_tz":-540,"elapsed":665,"user":{"displayName":"Noboru Koike","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggp8njUb4jc54JrzfM5cQBkfiCdlz6nY17y8-1szg=s64","userId":"05156582812995850159"}}},"source":["#gan.plot_hisotry()\n","\n","#gan.save_models()"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"P95nomvfwHrb"},"source":[""],"execution_count":null,"outputs":[]}]}